# 1 When should you use AI for assistance, and when should you rely on your own skills?

I Think I should use AI for such tasks as : generating setup for a new Python test file, creating some dummy data (JSON payloads), explaining cryptic error messages, or writing regex patterns. I must rely on my own skills for "context and correctness": understanding the specific business logic of Focus Bear, deciding what needs to be tested (test strategy), and verifying that the code actually does what it claims. AI can write a function, but only I can judge if that function fits the project architecture

# 2 How can you avoid over-reliance on AI while still benefiting from it?

I will try to write the logic or script myself first to ensure I understand the underlying concepts (especially since I am learning Python automation). Only after I have a draft (or if I am completely stuck) will I ask AI to "refactor this for better performance" or "fix the syntax error".

# 3 What steps will you take to ensure data privacy when using AI tools?

1. Never paste real customer info, API keys, passwords, or internal IP addresses into an AI prompt.
2. Replace sensitive data with generic placeholders (something like [DB_TABLE]).
3. Do not give all possible rights to AI agents in VS code, only those I need the most, and better to approve them manualy

## Document one best practice you will follow when using AI tools at Focus Bear.

I will treat every line of code generated by AI as "suspect" until proven innocent.
I will never copy-paste AI code directly into the main repository.
I must always run it locally, understand exactly how it works, and verify it passes the linter before pushing it to GitHub.
If I cannot explain the code to my mentor, I will not use it
